{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries to process video to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/openai/whisper.git \n",
    "#!sudo apt update && sudo apt install ffmpeg\n",
    "%pip install librosa\n",
    "\n",
    "import whisper\n",
    "import time\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import re\n",
    "import os\n",
    "\n",
    "# model = whisper.load_model(\"tiny.en\")\n",
    "# model = whisper.load_model(\"base.en\")  \n",
    "model = whisper.load_model(\"small.en\") # load the small model\n",
    "# model = whisper.load_model(\"medium.en\")\n",
    "# model = whisper.load_model(\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of video files from the WhisperVideo folder\n",
    "video_files = os.listdir(\"/data/WhisperVideo/\")\n",
    "\n",
    "# Loop through the video files and transcribe them\n",
    "for video_file in video_files:\n",
    "\n",
    "  # Skip the file if it is not a video format\n",
    "  if not video_file.endswith((\".mp4\", \".mov\", \".avi\", \".mkv\")):\n",
    "    continue\n",
    "\n",
    "  # Extract the audio from the video file using librosa\n",
    "  video_path = \"/WhisperVideo/\" + video_file\n",
    "  audio_path = \"/data/AudioFiles/\" + video_file[:-4] + \".wav\" # Replace the video extension with .wav\n",
    "\n",
    "\n",
    "  y, sr = librosa.load(video_path, sr=16000) # Load the audio with 16 kHz sampling rate\n",
    "  sf.write(audio_path, y, sr) # Save the audio as a wav file\n",
    "\n",
    "  # Transcribe the audio file using Whisper\n",
    "  result = model.transcribe(audio_path)\n",
    "  text = result[\"text\"].strip()\n",
    "  text = text.replace(\". \", \".\\n\\n\")\n",
    "\n",
    "  # Save the transcription as a text file in Google Docs\n",
    "  text_file = video_file[:-4] + \".txt\" # Replace the video extension with .txt\n",
    "  text_path = \"/data/transcript/\" + text_file\n",
    "  with open(text_path, \"w\") as f:\n",
    "    f.write(text)\n",
    "\n",
    "  # Move the video file to the ProcessedVideo folder\n",
    "  processed_path = \"/data/ProcessedVideo/\" + video_file\n",
    "  os.rename(video_path, processed_path)\n",
    "\n",
    "  # Print a message to indicate the progress\n",
    "  print(f\"Processed {video_file} and saved the transcription as {text_file}\")\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:50:36) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98e2bfb919ff5917b98b90a86d4547b4b7593f6b54c8d2e707cb1748df7f4086"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
